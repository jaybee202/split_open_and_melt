{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tkinter import filedialog \n",
    "import time\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that opens a filedialog box and returns the file selected by the user\n",
    "def get_filename():\n",
    "    filename = filedialog.askopenfilename(initialdir = \"/\", title = \"Select a File\") \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that opens a filedialog box and returns the file selected by the user\n",
    "def set_filename():\n",
    "    filename = filedialog.askopenfilename(initialdir = \"/\", title = \"Select a File\") \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that splits the filename provided by the user and tests to see if it exists in the list of\n",
    "#usable filetypes.  As of now these include xlsx, csv, and pickle.  Future updates will include SQL inputs.\n",
    "def get_filetype(filename):\n",
    "    filetype = filename.split('.')[-1]\n",
    "    \n",
    "    usable_filetypes = ['xlsx', 'csv', 'pickle']\n",
    "    \n",
    "    if filetype in usable_filetypes:\n",
    "        return filetype\n",
    "    else:\n",
    "        print('Sorry, I cannot process this filetype.  Please select a filetype from the list below' + \n",
    "              ' or edit this script:\\n')\n",
    "        for ft in usable_filetypes:\n",
    "            print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For xlsx files with more than one sheet, this function captures user selection for which sheet to import\n",
    "def get_xl_sheet_name(filename):\n",
    "    print('You entered an Excel file with more than one sheet. \\n' + \n",
    "          'Please enter the number of the sheet you wish to split open and melt: \\n')\n",
    "    \n",
    "    xl = pd.ExcelFile(filename)\n",
    "    \n",
    "    if len(xl.sheet_names) == 1:\n",
    "        return xl_sheet_names(0)\n",
    "    \n",
    "    else:\n",
    "        sheet_dict = {}\n",
    "        i = 1\n",
    "        for x in xl.sheet_names:\n",
    "            sheet_dict[str(i)] = x\n",
    "            print(str(i) + ': ' + x)\n",
    "            i += 1\n",
    "\n",
    "        sheet_key = str(input())\n",
    "        return sheet_dict[sheet_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from a xlsx file\n",
    "def get_df_from_xl(filename, sheet):\n",
    "    df = pd.read_excel(filename, sheet_name = sheet, header=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from a csv file\n",
    "def get_df_from_csv(filename):\n",
    "    df = pd.read_csv(filename, header = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from a pickle file\n",
    "def get_df_from_csv(filename):\n",
    "    df = pd.read_pickle(filename, header = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I will split open and melt an xlsx or csv file for you.\n",
      "Please be advised, I ASSUME YOU INCLUDE COLUMN HEADERS IN THE FIRST ROW!\n",
      "Select your file...\n"
     ]
    }
   ],
   "source": [
    "#Main script\n",
    "print('Hello, I will split open and melt an xlsx or csv file for you.\\n' + \n",
    "      'Please be advised, I ASSUME YOU INCLUDE COLUMN HEADERS IN THE FIRST ROW!\\n' +\n",
    "      'Select your file...')\n",
    "time.sleep(1)\n",
    "\n",
    "#Un-comment line below for production, for now, using hardcoded filename for development\n",
    "filename = get_filename()\n",
    "\n",
    "#Hardcoded filename for development purposes\n",
    "# filename = '/Users/algrhythm/py_rojects/split_open_and_melt/dummy_data.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetype = get_filetype(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You entered an Excel file with more than one sheet. \n",
      "Please enter the number of the sheet you wish to split open and melt: \n",
      "\n",
      "1: Use This Sheet\n",
      "2: Extra Sheet\n",
      "3: Sheet 1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "if filetype == 'xlsx':\n",
    "    sheet = get_xl_sheet_name(filename)\n",
    "    df = get_df_from_xl(filename, sheet)\n",
    "elif filetype == 'csv':\n",
    "    df = get_df_from_csv(filename)\n",
    "else:\n",
    "    df = get_df_from_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available columns are listed below.\n",
      "Enter the number of the column headers you wish to melt into rows and enter any non-number to continue:\n",
      "1: Col1\n",
      "2: Col2\n",
      "3: Col3\n",
      "4: Col4\n",
      "5: Col5\n",
      "6: Col6\n",
      "7: Col7\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "\n",
      "I will melt the following columns into row values:\n",
      "\n",
      "4: Col4\n",
      "5: Col5\n",
      "6: Col6\n",
      "7: Col7\n"
     ]
    }
   ],
   "source": [
    "#Prompt user to enter columns to melt into rows\n",
    "print('The available columns are listed below.\\n' + \n",
    "      'Enter the number of the column headers you wish to melt into rows and enter any non-number to continue:')\n",
    "\n",
    "#Provide all column headers to inlcude a number to be entered by the user\n",
    "col_dict = {}\n",
    "i = 1\n",
    "for c in df.columns:\n",
    "    col_dict[str(i)] = c\n",
    "    print(str(i) + ': ' + c)\n",
    "    i += 1\n",
    "\n",
    "#While the user enters valid values, those are added to a list for melting\n",
    "#Any invalid entry ends the while loop\n",
    "user_cols_num = []\n",
    "user_input = str(input())\n",
    "\n",
    "while user_input in col_dict.keys():\n",
    "    user_cols_num.append(user_input)\n",
    "    user_input = str(input())\n",
    "    \n",
    "user_col_names = []\n",
    "    \n",
    "#Show user what columns will be melted into rows\n",
    "print('\\nI will melt the following columns into row values:\\n')\n",
    "for uc in user_cols_num:\n",
    "    print(uc + ': ' + col_dict[uc])\n",
    "    user_col_names.append(col_dict[uc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the id values prior to melting\n",
    "id_vals = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if c not in user_col_names:\n",
    "        id_vals.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melt the df\n",
    "df_melt = df.melt(id_vars = id_vals, \n",
    "                  value_vars = user_col_names, \n",
    "                  var_name = 'melted_name', \n",
    "                  value_name = 'melted_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use original filename to get the original folder where outfile is saved (as csv)\n",
    "out_list = filename.split('/')\n",
    "out_list.reverse()\n",
    "out_list = out_list[1:-1]\n",
    "out_list.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = ''\n",
    "\n",
    "for ss in out_list:\n",
    "    outfile = outfile + '/' + ss\n",
    "    \n",
    "outfile = outfile + '/' + filename.split('/')[-1].split('.')[0] + '_split_open_and_melted.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt.to_csv(outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
